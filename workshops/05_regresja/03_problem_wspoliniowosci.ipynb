{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9AQrOdajQbU_"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","from scipy import stats\n","from patsy import dmatrices\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"Rh2so0xcQbVB"},"source":["# Problem współliniowości"]},{"cell_type":"markdown","metadata":{"id":"AsR3vrUUQbVD"},"source":["### Diagnostyka\n","\n","1. **Macierz korelacji predyktorów** - $D_X = (\\rho_{ij})$;\n","\n","2. **Uwarunkowanie macierzy** $\\frac{\\lambda_{\\text{max}}(D_X)}{\\lambda_{\\text{min}}(D_X)}$ - duże $\\implies$ istnieje para predyktorów zależnych liniowo;\n","\n","3. **VIF** (ang. *variance inflation factor*) - współczynnik podbicia wariancji\n","\n","    Dla $1\\leq i \\leq p-1$: $$R^2_i = \\frac{\\text{RSS}}{\\text{TSS}}$$ dla modelu $x_i \\sim x_{-i}$, gdzie $x_{-i}$ oznacza wszystkie zmienne objaśniające z  pominięciem $i$-tej.\n","\n","    Wówczas\n","    $$\n","    \\text{VIF}_i = \\frac{1}{1-R_i^2}\n","    $$\n","\n","    **Interpretacja:** Duża wartość dla pewnego $i$ wskazuje na potencjalną liniową zależność $i$-tej zmiennej objaśniającej od pozostałych zmiennych. \n","\n","    **Reguła kciuka:** Jeśli $\\text{VIF}_i\\geq 10$, to $i$-tą zmienną uznajemy w przybliżeniu liniowo zależną od pozostałych."]},{"cell_type":"markdown","metadata":{"id":"ldihMp89QbVE"},"source":["# Zadanie 1\n","Dla danych `Carseats` sprawdź, czy występuje w nich problem współliniowości przy użyciu powyższych metod. Jeśli tak, odrzuć ze zbioru zmienne zależne liniowo i dopasuj model regresji liniowej bez nich. Porównaj wyniki."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYuM4Xz0QbVE"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"w4lwRB6vQbVI"},"source":["# Zadanie 2\n","Wczytaj dane `kc_house_data.csv` ([This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015](https://www.kaggle.com/harlfoxem/housesalesprediction/data)).\n","\n","Dopasuj model `price ~ bathrooms + sqft_living + sqft_lot + sqft_above + sqft_basement + lat + long`, uwzględnij współliniowość predyktorów."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTtw3DhiQbVJ"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"jh1bhUQJQbVK"},"source":["# Zadanie 3\n","Wczytaj zbiór `Hald.csv`. Znajdź najlepszy model regresji liniowej uwzględniając współliniowość predyktorów.\n","\n","Opis zbioru:\n","\n","    Heat evolved during setting of 13 cement mixtures of four basic ingredients. Each ingredient percentage appears to be rounded down to a full integer. The sum of the four mixture percentages varies from a maximum of 99% to a minimum of 95%. If all four regressor X-variables always summed to 100%, the centered X-matrix would then be of rank only 3. Thus, the regression of heat on four X-percentages is ill-conditioned, with an approximate rank deficiency of MCAL = 1. The first column is the response and the remaining four columns are the predictors."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQYZiOJGQbVL"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"MFrrx4Z_QbVM"},"source":["# Obserwacje odstające"]},{"cell_type":"markdown","metadata":{"id":"NOcJ0JWHQbVM"},"source":["### Diagnostyka\n","\n","Obserwacja odstająca (ang.outlier) jest obserwacją, która nie spełnia równania regresji czyli nie należy do modelu regresji. Obserwacje odstające mogą znacząco wpływać na postać prostej regresji.\n","\n","**Rezyduum** $e_i$ przyjmuje dla $i$-tej obserwacji wartość różnicy:\n","$$\n","e_i = y_i - \\hat{y}_i.\n","$$\n","\n","**Błąd standardowy** takiego rezyduum $e_i$ jest równy:\n","$$\n","\\text{SE}(e_i) = S\\cdot\\sqrt{1-h_i},\n","$$\n","gdzie \n","- $S = \\sigma$ oznacza przęciętne odchylenie wartości rzeczywistych od wartości przewidywanych,\n","- $h_i$ - wartość wpływu $i$-tej obserwacji, która wyraża się wzorem\n","$$\n","h_i = \\frac{1}{n} + \\frac{(x_i - \\overline{x})^2}{\\sum_{i=1}^n(x_i - \\overline{x})^2}\n","$$\n","\n","Obserwacje odstajacę dzielimy na \n","    - wpływowe - obserwacja jest wpływowa jesli jej usuniecie z modelu ma duży wpływ na dopasowanie modelu/prognoże na podstawie modelu;\n","    - niewpływowe - obserwacja jest niewpływowa jesli jej usuniecie z modelu nie ma wpływu na dopasowanie modelu/prognoże na podstawie modelu;\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xokmHX_3QbVN"},"outputs":[],"source":["model = smf.ols('Sales ~ ShelveLoc + CompPrice + Income +  Advertising + Price + Age', data=carseats_df)\n","fitted_model = model.fit()\n","fitted_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"sNnQ7otuQbVN"},"source":["  \n","### Detekcja obserwacji odstających:\n","\n","1. **Wykres studentyzowanych rezyduów**\n","\n","Dla małych prób, wartości zmiennej objaśniającej nie są w miarę równomiernie rozłożone i niektóre błędy $\\text{SE}(e_i)$ mogą znacznie odbierać od błędu $S$. Wówczas dobrze jest analizować rezydua przy użyciu tzw. **rezyduów studentyzowanych**.\n","\n","$$r_i =\\frac{e_i}{\\text{SE}(e_i)}$$\n","\n","To pozwoli wykrywać obserwacje faktycznie odstające, pomijając te, które przy analizie rezyduów $e_i$ sugerowały, że są odstające mimo, że takimi nie były. Dla rezyduów studentyzowanych zakłada się, że przy poziomie ufności równym 0.95 uznaje się je za normalne (zachowujące własność rozkładu normalnego), gdy należą do przedziału $[−2,+2]$.\n","\n","Wykres studentyzowanych rezyduów względem ich indeksu identyfikuje duże wartości, które przypuszczalnie odpowiadają obserwacjom odstającym. Metodata nie sprawdzi się w sytuacji, gdy mamy w analizowanym zbiorze obserwację wpływową o małej wartości $e_i$. Wówczas bowiem nie określimy jej jako odstającej mimo, że taka w istocie jest."]},{"cell_type":"markdown","metadata":{"id":"fBDUcQ59QbVP"},"source":["2. **Wpływowość**\n","\n","Wpływ $i$-tej obserwacji $h_i$ określamy wzorem\n","$$\n","h_i = \\frac{1}{n} + \\frac{(x_i - \\overline{x})^2}{\\sum_{i=1}^n(x_i - \\overline{x})^2},\n","$$ \n","który określa odstępstwo $x_i$ od $\\overline{x}$.\n","\n","Dla modelu o $p$ parametrach (gdzie $p$ to łączna liczba zmiennych objaśniających i objaśnianych), obserwację uznajemy za wpływową jeśli \n","$$\n","h_i \\geq \\frac{2p}{n}.\n","$$"]},{"cell_type":"markdown","metadata":{"id":"FWh3TKXPQbVP"},"source":["3. **Odległość Cooka**\n","\n","Jest to miara stopnia zmiany współczynników regresji, gdyby dany przypadek pominąć w obliczeniach współczynników:\n","$$\n","D_i = \\frac{\\sum_{j=1}^n(\\hat{Y}_j - \\hat{Y}_{j(i)})^2}{pS^2},\n","$$\n","gdzie $\\hat{Y}_j$ - prognoza na podstawie pełnych danych, $\\hat{Y}_{j(i)}$ - prognoza bez $i$-tej obserwacji.\n","\n","**Interpretacja**: Duża wartość $D_i$ wskazuje na znaczy wpływ usunięcia $i$-tej obserwacji, czyli $i$-ta obserwacja jest obserwacją wpływową.\n","\n","Wszystkie wartości dla danej odległości powinny być tego samego rzędu. Jeśli tak nie jest, to prawdopodobnie dany przypadek ma istotnie duży wpływ na obciążenie równania regresji.\n","\n","**Reguła kciuka**: $D_i > \\frac{4}{(n − p − 1)}$"]},{"cell_type":"markdown","metadata":{"id":"9xiJa-NJQbVQ"},"source":["# Zadanie 4\n","Przeanalizuj obserwacje odstające w modelu `model` dla danych `Carseats`. Zidentyfikuj obserwacje im odpowiadające, usuń je ze zbioru i zbuduj model ponownie. Porównaj dopasowanie modeli. \n","Analogicznie postępuj dla modelu `model2`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75UERXRxQbVQ"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"03_problem_wspoliniowosci.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}